{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed21481a-973f-4fdc-a869-e779272b9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 29 21:20:06 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   78C    P3              11W /  35W |    431MiB /  4096MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1190      G   /usr/lib/xorg/Xorg                          231MiB |\n",
      "|    0   N/A  N/A      1853      G   cinnamon                                     68MiB |\n",
      "|    0   N/A  N/A     12170      G   ...f2e0985358b81539ac6de00685921ee46ee      109MiB |\n",
      "|    0   N/A  N/A     17611      G   /usr/bin/blackbox-terminal                   11MiB |\n",
      "|    0   N/A  N/A     17947      G   /home/hasnan/anaconda3/bin/python             1MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539140bd-b743-4646-b9fc-bf1298d8bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hasnan/Downloads/Notebook/HelmetPlusLicense\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f893193-3605-44f4-8590-64ee16642a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.7 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3904MiB)\n",
      "Setup complete âœ… (12 CPUs, 15.3 GB RAM, 187.2/361.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01149ca8-596a-41f5-9c66-bebdd17ae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f59a10-face-4ef7-a675-c1f6dc82f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "licence_model = YOLO('/home/hasnan/Downloads/Notebook/runs/detect/train8/weights/best.pt')\n",
    "helmet_model = YOLO('/home/hasnan/Downloads/Notebook/Licence/runs/detect/train3/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d8fc625-be34-4fd5-ad41-56d3220659a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test print\n",
    "\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en'])\n",
    "test_image = '/home/hasnan/Downloads/Notebook/test_1.jpg'\n",
    "easyocr_results = reader.readtext(test_image)\n",
    "for (bbox, text, confidence) in easyocr_results:\n",
    "    print(f\"Text: {text}, Confidence: {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a6b03e7-0c84-4cc3-8574-867af203765a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 (no detections), 6.2ms\n",
      "Speed: 1.5ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "No violations: Helmet detected.\n",
      "Violations: []\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "#\n",
    "# Initialize models\n",
    "licence_model = YOLO('/home/hasnan/Downloads/Notebook/runs/detect/train8/weights/best.pt')\n",
    "helmet_model = YOLO('/home/hasnan/Downloads/Notebook/Licence/runs/detect/train3/weights/best.pt')\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])  # Use 'bn' for Bengali if applicable\n",
    "\n",
    "# List to store detected violations\n",
    "violations = []\n",
    "detected_plates = set()  # To store unique license plates\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    global violations, detected_plates\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Detect objects using the helmet model\n",
    "    detections = helmet_model(image, conf=0.25)\n",
    "\n",
    "    # Separate detections into persons and helmets\n",
    "    person_boxes = [box for box in detections[0].boxes if box.cls == 1]  # Adjust class index for persons\n",
    "    helmet_boxes = [box for box in detections[0].boxes if box.cls == 0]  # Adjust class index for helmets\n",
    "\n",
    "    # Check if a helmet is worn by any detected person\n",
    "    if not person_boxes and helmet_boxes:\n",
    "        print(\"Violation detected: No helmet.\")\n",
    "        reader = easyocr.Reader(['en'])\n",
    "        easyocr_results = reader.readtext(image_path)\n",
    "        for (bbox, text, confidence) in easyocr_results:\n",
    "            violations.append(text)\n",
    "    else:\n",
    "        print(\"No violations: Helmet detected.\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = '/home/hasnan/Downloads/Notebook/steptodown.com873783.jpg'  # Replace with your test image path\n",
    "process_image(image_path)\n",
    "\n",
    "print(\"Violations:\", violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f322d3ee-2d8f-4ed4-9c99-abb40fbc7a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 driver, 1 no-helmet, 10.6ms\n",
      "Speed: 1.3ms preprocess, 10.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Violations: []\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "# Initialize models\n",
    "helmet_model = YOLO('/home/hasnan/Downloads/Notebook/runs/detect/train8/weights/best.pt')\n",
    "licence_model = YOLO('/home/hasnan/Downloads/Notebook/Licence/runs/detect/train3/weights/best.pt')\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])  # Use 'bn' for Bengali if applicable\n",
    "\n",
    "# List to store detected violations\n",
    "violations = []\n",
    "detected_plates = set()  # To store unique license plates\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    global violations, detected_plates\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Detect objects using the helmet model\n",
    "    detections = helmet_model(image, conf=0.25)\n",
    "\n",
    "    # Separate detections into persons, helmets, and bikes\n",
    "    bike_boxes = [box for box in detections[0].boxes if box.cls == 2]  # Adjust class index for bikes\n",
    "    person_boxes = [box for box in detections[0].boxes if box.cls == 1]  # Adjust class index for persons\n",
    "    helmet_boxes = [box for box in detections[0].boxes if box.cls == 0]  # Adjust class index for helmets\n",
    "\n",
    "    for bike in bike_boxes:\n",
    "        bx1, by1, bx2, by2 = map(int, bike.xyxy[0])\n",
    "        nearby_persons = [\n",
    "            person for person in person_boxes if calculate_overlap(bike, person) > 0.3\n",
    "        ]\n",
    "\n",
    "        if nearby_persons and not helmet_boxes:\n",
    "            print(\"Violation detected: No helmet for a bike rider.\")\n",
    "            reader = easyocr.Reader(['en'])\n",
    "            easyocr_results = reader.readtext(image_path)\n",
    "\n",
    "            for (bbox, text, confidence) in easyocr_results:\n",
    "                print(f\"Text: {text}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "                # Avoid duplicate entries\n",
    "                if text not in detected_plates:\n",
    "                    detected_plates.add(text)\n",
    "                    violations.append(text)\n",
    "        else:\n",
    "            print(\"No violations: Helmet detected or no bike nearby.\")\n",
    "\n",
    "\n",
    "def calculate_overlap(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate the overlap ratio between two bounding boxes.\n",
    "    :param box1: YOLO box 1\n",
    "    :param box2: YOLO box 2\n",
    "    :return: Overlap ratio (IoU)\n",
    "    \"\"\"\n",
    "    x1 = max(box1.xyxy[0][0], box2.xyxy[0][0])\n",
    "    y1 = max(box1.xyxy[0][1], box2.xyxy[0][1])\n",
    "    x2 = min(box1.xyxy[0][2], box2.xyxy[0][2])\n",
    "    y2 = min(box1.xyxy[0][3], box2.xyxy[0][3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    # Compute areas of both boxes\n",
    "    box1_area = (box1.xyxy[0][2] - box1.xyxy[0][0]) * (box1.xyxy[0][3] - box1.xyxy[0][1])\n",
    "    box2_area = (box2.xyxy[0][2] - box2.xyxy[0][0]) * (box2.xyxy[0][3] - box2.xyxy[0][1])\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "\n",
    "# Example usage\n",
    "#image_path = '/home/hasnan/Downloads/Notebook/steptodown.com873783.jpg'\n",
    "image_path = '/home/hasnan/Downloads/Notebook/helmet-detection-18/train/images/28_jpg.rf.b444b6d15f1f62e74169c3f22d3b34c0.jpg'\n",
    "process_image(image_path)\n",
    "\n",
    "print(\"Violations:\", violations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d4824683-2f99-433a-b233-049d171a4f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 driver, 1 helmet, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "No violations: No person detected riding the bike.\n",
      "Violations: []\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "helmet_model = YOLO('/home/hasnan/Downloads/Notebook/runs/detect/train8/weights/best.pt')\n",
    "licence_model = YOLO('/home/hasnan/Downloads/Notebook/Licence/runs/detect/train3/weights/best.pt')\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "violations = []\n",
    "detected_plates = set()\n",
    "\n",
    "def process_image(image_path):\n",
    "    global violations, detected_plates\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    detections = helmet_model(image, conf=0.25)\n",
    "\n",
    "    bike_boxes = [box for box in detections[0].boxes if box.cls == 2]\n",
    "    person_boxes = [box for box in detections[0].boxes if box.cls == 1]\n",
    "    helmet_boxes = [box for box in detections[0].boxes if box.cls == 0]\n",
    "\n",
    "    for bike in bike_boxes:\n",
    "        bx1, by1, bx2, by2 = map(int, bike.xyxy[0])\n",
    "        nearby_persons = [\n",
    "            person for person in person_boxes if calculate_overlap(bike, person) > 0.3\n",
    "        ]\n",
    "\n",
    "        if nearby_persons:\n",
    "            rider = nearby_persons[0]\n",
    "\n",
    "            helmet_near_rider = False\n",
    "            rider_head_box = get_head_box(rider)\n",
    "\n",
    "            for helmet in helmet_boxes:\n",
    "                if calculate_overlap(rider_head_box, helmet) > 0.3:\n",
    "                    helmet_near_rider = True\n",
    "                    break\n",
    "\n",
    "            if not helmet_near_rider:\n",
    "                easyocr_results = reader.readtext(image_path)\n",
    "\n",
    "                for (bbox, text, confidence) in easyocr_results:\n",
    "                    if text not in detected_plates:\n",
    "                        detected_plates.add(text)\n",
    "                        violations.append(text)\n",
    "            else:\n",
    "                print(\"No violations: Helmet detected near rider's head.\")\n",
    "        else:\n",
    "            print(\"No violations: No person detected riding the bike.\")\n",
    "\n",
    "def calculate_overlap(box1, box2):\n",
    "    x1 = max(box1.xyxy[0][0], box2.xyxy[0][0])\n",
    "    y1 = max(box1.xyxy[0][1], box2.xyxy[0][1])\n",
    "    x2 = min(box1.xyxy[0][2], box2.xyxy[0][2])\n",
    "    y2 = min(box1.xyxy[0][3], box2.xyxy[0][3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    box1_area = (box1.xyxy[0][2] - box1.xyxy[0][0]) * (box1.xyxy[0][3] - box1.xyxy[0][1])\n",
    "    box2_area = (box2.xyxy[0][2] - box2.xyxy[0][0]) * (box2.xyxy[0][3] - box2.xyxy[0][1])\n",
    "\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "def get_head_box(person_box):\n",
    "    px1, py1, px2, py2 = map(int, person_box.xyxy[0])\n",
    "    head_height = (py2 - py1) // 3  # Adjusted to estimate the head area as one-third of the person's bounding box height\n",
    "    return [px1, py1, px2, py1 + head_height]\n",
    "\n",
    "image_path = '/home/hasnan/Downloads/Notebook/steptodown.com873783.jpg'\n",
    "process_image(image_path)\n",
    "\n",
    "print(\"Violations:\", violations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
